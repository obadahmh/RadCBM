\subsection{Experimental Setup}
We evaluate \radcbm on MIMIC-CXR (377k images, 227k reports) \cite{johnson2019mimic} and CheXpert (224k images) \cite{irvin2019chexpert}.
Reports are split at the study level to avoid leakage.
The concept vocabulary is mined only from training reports and filtered to chest anatomy and radiographic findings that appear at least 50 times.
Images are resized to $320\times320$ and processed by a DenseNet-121 backbone initialized from ImageNet.
Region and finding heads use sigmoid outputs; $\lambda_1$ and $\lambda_2$ are tuned on a held-out set.

\subsection{Baselines}
\textbf{Black-box CNN:} a DenseNet-121 trained end-to-end on labels only.
\textbf{Flat CBM:} a concept bottleneck without hierarchy or gating; all concepts are predicted jointly and feed a linear label head.
\textbf{CheXpert CBM:} a CBM trained on the 14 CheXpert labeler concepts rather than RadGraph-mined concepts.
\textbf{Post-hoc CBM:} a model that predicts concepts after training but does not constrain the label pathway.

\subsection{Metrics}
Classification is measured with per-class and macro AUC-ROC and F1.
Concept quality is measured with concept AUC (predicting report-derived concepts from images) and concept accuracy at a tuned threshold.
Interpretability is assessed via intervention faithfulness (does editing a concept change the label as expected?) and plausibility (fraction of activated findings whose region abnormality exceeds 0.5).

\subsection{Main Results}
Automated concept mining provides broad coverage of radiographic findings without manual effort.
On both datasets, the hierarchical CBM improves concept AUC over the flat CBM and cuts implausible activations (for example, suppressing lung findings when the lung is predicted normal) through gating.
Classification AUC matches the black-box CNN within the variance of cross-validation while exposing a linear map from concepts to labels.
Compared to the post-hoc CBM, \radcbm yields higher intervention faithfulness because concepts lie on the prediction path rather than being auxiliary outputs.

\subsection{Ablations}
\textbf{Hierarchy vs. flat:} removing the hierarchy reduces concept AUC and increases false positives in normal regions.
\textbf{Gating vs. concatenation:} replacing multiplicative gating with concatenation increases label AUC slightly but decreases plausibility and hurts intervention faithfulness.
\textbf{Uncertainty handling:} treating uncertain targets as soft labels outperforms discarding them, improving calibration for rare findings.
\textbf{Concept frequency threshold:} lowering the frequency threshold increases vocabulary size but introduces noisy concepts that degrade both concept and label metrics.

\subsection{Qualitative Analysis}
Case studies show region-first explanations that mirror radiologist reports.
For a pneumonia prediction, the model highlights high lung abnormality with opacity and consolidation findings contributing most to the label, while pleural effusion activation remains low.
Manual edits, such as forcing effusion to zero, reduce the pneumonia score as expected, illustrating controllable, faithful reasoning.
