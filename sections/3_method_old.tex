% =============================================================================
% RadCBM Methods Section
% =============================================================================
\label{sec:method}

\subsection{Overview}
\radcbm\ is a two-stage concept bottleneck model for chest radiographs trained from report-derived, ontology-grounded concepts.
We first distill a concept bank from free-text radiology reports by extracting entities and assertions with RadGraph-XL~\cite{jain2021radgraph}, linking mentions to UMLS CUIs using SapBERT~\cite{liu2021sapbert} under radiology-specific ontology constraints, and pruning the resulting inventory into a trainable vocabulary.
Using this bank, we train (i) an image$\to$concept predictor with \emph{mention-masked} supervision and (ii) a concept$\to$label head for downstream diagnoses.
The central architectural choice is an anatomy-first hierarchy: each concept is assigned to a coarse anatomical region, a region head predicts abnormality probabilities, and these probabilities multiplicatively gate concept activations before label prediction.
To make explanations intrinsic rather than post hoc, the hierarchical diagnosis head is constrained to be a bias-free linear function of gated concepts.

\subsection{Problem Setup and Notation}
Let $\mathcal{D}=\{(x_i,r_i,y_i)\}_{i=1}^N$ denote a dataset of chest radiographs $x_i$, associated reports $r_i$ (when available), and multi-label targets $y_i\in\{0,1,-1\}^L$ for $L$ clinical labels (CheXpert-style), where $-1$ denotes uncertainty or missingness.
\radcbm\ predicts labels \emph{through} an explicit concept vector over a bank $\mathcal{C}=\{c_1,\dots,c_K\}$ distilled from reports.

\paragraph{Concept supervision as partial labels.}
Reports are incomplete: failure to mention a concept is not evidence of absence.
We therefore encode concept supervision per study as a multi-assertion state $a_{ik}\in\{0,1,2,3\}$ for (unmentioned, absent, uncertain, present), and derive a target $t_{ik}\in\{0,0.5,1\}$ and mention mask $m_{ik}\in\{0,1\}$.
Unmentioned concepts are masked ($m_{ik}=0$); absent and present are supervised as negatives/positives; uncertain can be either ignored (masked) or treated as a soft target ($t_{ik}=0.5$) with down-weighted loss.

\subsection{Ontology-Grounded Concept Distillation from Reports}
\paragraph{Entity extraction and assertion.}
We run RadGraph-XL~\cite{jain2021radgraph} over report findings/impression text to extract entity spans with assertion status (\emph{present}, \emph{absent}, \emph{uncertain}).
For each mention, we also collect modifier spans connected via RadGraph relations (e.g., laterality and anatomical descriptors) and convert them into a normalized free-text location string.

\paragraph{Entity linking to UMLS/SNOMED.}
Each extracted mention is linked to a UMLS Concept Unique Identifier (CUI) using SapBERT~\cite{liu2021sapbert} embeddings and nearest-neighbor retrieval over a prebuilt index of UMLS synonym strings.
To reduce off-domain matches, we restrict candidate strings to radiology-relevant semantic types (findings and anatomy) and constrain ontology sources to SNOMED CT terms~\cite{bodenreider2004umls,donnelly2006snomed}.
We embed both the mention surface form and the mention concatenated with its modifier tokens, then keep the highest-scoring candidate above a similarity threshold (default 0.8), discarding low-confidence links.

\paragraph{Per-study concept sets and inventory.}
We aggregate linked mentions into a per-study concept set, storing the canonical concept name, the CUI, the assertion status, and the derived location string.
When multiple mentions map to the same concept, we keep the highest-precedence assertion (present $\succ$ uncertain $\succ$ absent) to avoid contradictory supervision when constructing study-level labels.
Aggregating across studies yields a concept inventory with frequencies, supported assertions, and observed locations.

\paragraph{Pruning and concept supervision tensors.}
To obtain a CBM-friendly vocabulary, we prune the inventory by category (findings by default) and frequency (e.g., at least 10 total occurrences with at least one positive mention), with optional name-based filters.
The resulting pruned bank defines an ordered index of $K$ concepts and a dense study$\times$concept label matrix.
We store concept labels in the multi-assertion encoding above and convert them into $(t_{ik},m_{ik})$ on the fly for mention-masked training.
In our current bank, this procedure yields $K=1{,}312$ ontology-grounded findings.

\subsection{Anatomical Regions and Pooled Region Targets}
We introduce a coarse anatomical partition $\mathcal{R}$ (lung, pleura, heart, mediastinum, bone; with an \texttt{other} bucket) and assign each concept $k$ to a region $g(k)\in\mathcal{R}$.
The concept$\to$region map is generated deterministically from the pruned concept bank using (in order) cues from the concept's supported location strings, name-based patterns (e.g., \texttt{pleur}, \texttt{pulmon}, \texttt{mediastin}), and semantic type; concepts without reliable cues fall back to \texttt{other}.
This produces a fixed hierarchy shared across all hierarchical components.

Given any concept-valued vector $v\in[0,1]^K$, we define pooled region scores by max-pooling over the concepts assigned to each region:
\begin{equation}
\label{eq:region_pool}
P_r(v)=\max_{k:\,g(k)=r} v_k \quad \forall r\in\mathcal{R}.
\end{equation}
When report-derived concept supervision is available, we derive region targets $\tilde{z}_{ir}=P_r(t_i)$ and a corresponding region mask $\tilde{m}_{ir}$, which is 1 if any concept in region $r$ is explicitly mentioned ($m_{ik}=1$) and 0 otherwise.
If a region has no explicitly mentioned concept, it is treated as unknown ($\tilde{m}_{ir}=0$) and excluded from the region loss.
This uses no additional region annotations beyond the report-derived concept signal.

\subsection{RadCBM Architecture}
\radcbm\ follows a two-stage CBM design: an image$\to$concept predictor ($X\!\to\!C$) and a concept$\to$label head ($C\!\to\!Y$).
Both stages support region prediction and multiplicative gating through the shared concept$\to$region map.

\paragraph{Stage 1: Image$\to$concept prediction.}
A vision backbone maps an image to a feature vector $h=f_\theta(x)$ (MedCLIP~\cite{wang2022medclip} ViT/ResNet variants or ResNet backbones in our implementation).
A lightweight MLP head produces concept logits $s=g_\phi(h)$ and probabilities $\hat{c}=\sigma(s)$.
We train using mention-masked binary cross-entropy, supervising only concepts that are explicitly asserted in the report:
\begin{equation}
\label{eq:concept_loss}
\mathcal{L}_{\text{concept}}=
\frac{1}{\sum_{i,k} m_{ik}}\sum_{i,k} m_{ik}\;\mathrm{BCE}(s_{ik},t_{ik}).
\end{equation}
Uncertain mentions can be treated as soft targets with reduced weight; unmentioned concepts do not contribute to the loss.
When a region map is available, we additionally predict region logits from the concept vector, supervise them using pooled targets from Eq.~(\ref{eq:region_pool}) where available, and optionally clamp gates using these targets.

\paragraph{Stage 2: Concept$\to$label prediction.}
Given predicted concepts $\hat{c}\in[0,1]^K$, a diagnosis head outputs label logits $\ell=h_\psi(\hat{c})$ and probabilities $\hat{y}=\sigma(\ell)$.
We train the two stages sequentially: we first fit the concept predictor and export study-level concept probabilities, then train the diagnosis head using these probabilities as its input.

\paragraph{Hierarchical region-gated head.}
The hierarchical \radcbm\ head predicts region abnormality logits $u=W_r\hat{c}$ and region probabilities
\begin{equation}
\label{eq:region_probs}
\hat{z}=\sigma\!\left(\frac{u}{\tau}\right),\qquad
\hat{z}\leftarrow \epsilon+(1-\epsilon)\hat{z},
\end{equation}
where $\tau$ is a temperature and $\epsilon$ is an optional gate floor implementing conservative soft-gating.
Each concept is then gated by its parent region: $g_k=\hat{z}_{g(k)}$, yielding $\hat{c}^{\,\text{gated}}_k=g_k\,\hat{c}_k$.
Finally, labels are predicted by a \emph{bias-free linear} layer
\begin{equation}
\label{eq:linear_label_head}
\ell=W_y\hat{c}^{\,\text{gated}},
\end{equation}
so each label logit is a linear function of gated concept activations.
This constraint makes explanations intrinsic: the signed contribution of concept $k$ to label $\ell_j$ is $W_y[j,k]\;\hat{c}^{\,\text{gated}}_k$.

\paragraph{Gate clamping and region consistency.}
To reduce anatomically implausible activations, we optionally clamp region gates during training using pooled region targets.
When concept-level supervision is available (e.g., during concept-predictor training), we use $\tilde{z}_i$ from Eq.~(\ref{eq:region_pool}); when training the diagnosis head from predicted concepts, we use soft pooled targets $P_r(\hat{c})$ computed from the input concept vector.
In both cases, clamping is implemented by multiplying $\hat{z}$ with the available pooled target (treating unknown targets as neutral), enforcing that regions with no supporting evidence cannot open their gates.

\paragraph{Losses.}
The diagnosis head is trained with masked BCE on CheXpert-style labels (masking uncertain/missing entries as configured) plus an auxiliary region loss when pooled region targets are available:
\begin{equation}
\label{eq:cbm_loss}
\mathcal{L}_{\text{CBM}}=\mathcal{L}_{\text{label}}+\lambda_r\mathcal{L}_{\text{region}},
\end{equation}
where $\mathcal{L}_{\text{region}}$ is a BCE between region logits $u$ and pooled targets.

\paragraph{Optional ontology-aware regularization.}
To stabilize long-tail concept predictors, we optionally add a graph Laplacian penalty over the concept-head weights:
\begin{equation}
\label{eq:graph_reg}
\mathcal{L}_{\text{graph}}=\sum_{(p,q)\in E}\|w_p-w_q\|_2^2,
\end{equation}
where $E$ is a user-specified set of concept edges (e.g., within-region neighbors) and $w_p$ denotes the weight vector associated with concept $p$ in the concept head.
The total concept-stage objective becomes $\mathcal{L}_{\text{concept}}+\lambda_g\mathcal{L}_{\text{graph}}$.

\subsection{Interpretability and Concept Interventions}
Because \radcbm\ predicts concepts and uses them as the sole input to a constrained label head, it supports three complementary forms of inspection:
(i) \emph{concept readout} (predicted presence of each ontology-grounded concept),
(ii) \emph{region readout} (predicted region abnormality probabilities), and
(iii) \emph{attribution} via the linear contributions $W_y[j,k]\hat{c}^{\,\text{gated}}_k$.
We quantify anatomical plausibility by measuring the rate of \emph{implausible activations} (a concept predicted present while its parent region gate is low).
We further assess intervention behavior by editing concepts (setting selected $\hat{c}_k$ to 0 or 1) and measuring the induced change in $\hat{y}$; in intrinsic CBMs, the signed contributions in Eq.~(\ref{eq:linear_label_head}) provide a direct, testable hypothesis for these counterfactual effects.
