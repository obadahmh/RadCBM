\subsection{Deep Learning for Chest Radiography}

Large-scale datasets have driven rapid progress in automated chest radiograph interpretation. ChestX-ray14 provided over 100,000 images with NLP-derived labels~\cite{wang2017chestxray14}; CheXpert~\cite{irvin2019chexpert} and MIMIC-CXR~\cite{johnson2019mimiccxr} expanded scale while improving label quality and providing associated reports. Architectures from DenseNet-based CheXNet and CheXNeXt~\cite{rajpurkar2017chexnet,rajpurkar2018chexnext} to Vision Transformers~\cite{singh2024efficient,shamshad2023transformers} now match radiologist performance on common pathologies. Clinical adoption nevertheless lags, partly because these models offer predictions without reasoning. Post-hoc explanations, including saliency maps~\cite{simonyan2014saliency} and Grad-CAM~\cite{selvaraju2017gradcam}, show \emph{where} models attend but not \emph{what} they detect, failing to bridge the gap between neural activations and the conceptual vocabulary radiologists use~\cite{rudin2019stop}.

\subsection{Concept Bottleneck Models}

Concept Bottleneck Models (CBMs) address interpretability by routing predictions through human-interpretable intermediate representations~\cite{koh2020concept}. The model first predicts concept presence, then reasons from concepts to outputs, making the decision process transparent by construction. Extensions include post-hoc retrofitting of pretrained networks~\cite{yuksekgonul2023posthoc}, concept embeddings that relax strict bottlenecks~\cite{zarlenga2022cem}, and interactive variants enabling test-time correction~\cite{chauhan2023interactive}. Applications span dermatology~\cite{lucieri2020explaining}, ophthalmology~\cite{fauw2018clinically}, and radiology. The persistent limitation is concept acquisition: training requires annotations for every concept, and manual labeling at the granularity needed for clinical utility is prohibitively expensive~\cite{oikarinen2023labelfree}. Ontologies define concept vocabularies but not their image-level presence.

Recent work has sought to reduce dependence on manual concept labels and to better characterize the faithfulness and robustness of concept-based explanations. Label-free CBMs and language-guided bottlenecks align CLIP-style vision-language representations with concept predictors, discovering concepts and names without per-concept supervision~\cite{oikarinen2023labelfree,yang2023language}. Coarse-to-fine CBMs further introduce multilevel bottlenecks, tying coarse (global) concepts to fine (localized) concepts to capture low-level details while preserving interpretability~\cite{panousis2024coarsetofineconceptbottleneckmodels}. Visual TCAV and related approaches refine concept scoring and selection~\cite{desantis2024visualtcav}, while GlanceNets~\cite{marconato2022glancenets} and concept-shift analyses~\cite{kim2024shiftcbm} highlight structural and robustness limitations, showing that concept pipelines can still exploit shortcuts even when their explanations appear plausible. Our approach is complementary: rather than discovering concepts from generic image-text corpora, we construct an ontology-grounded concept bank directly from radiology reports and use it as the bottleneck for chest X-ray interpretation. Critically, while RadGraph and similar tools have become standard for \emph{evaluating} report generation systems via entity-level F1 scores~\cite{jain2021radgraph,jain2021radgraph}, they have not previously been used to \emph{supervise} concept bottleneck models. Our work bridges this gap, converting RadGraph's structured extraction into trainable concept targets with assertion status and anatomical localization.

\subsection{Clinical NLP for Radiology Reports}

Radiology reports encode concept information in natural language, motivating automated extraction. Rule-based systems like NegBio~\cite{peng2018negbio} and the CheXpert labeler~\cite{irvin2019chexpert} match patterns to identify findings and their assertion status. CheXbert improved on these using BERT fine-tuned on expert annotations~\cite{smit2020chexbert}, and RadGraph extended extraction to full entity-relation graphs~\cite{jain2021radgraph}. Assertion detection, distinguishing present, absent, and uncertain findings, remains critical, addressed by systems from NegEx~\cite{chapman2001negex} through modern neural classifiers~\cite{khandelwal2020negbert}. These tools extract increasingly structured information from reports, though integration into pipelines producing trainable concept banks remains underdeveloped.

\subsection{Biomedical Entity Linking}

Grounding extracted mentions in standardized terminologies normalizes linguistic variation and enables semantic reasoning. UMLS integrates over 200 vocabularies, including SNOMED CT, into a unified metathesaurus~\cite{bodenreider2004umls}. Neural linking methods, particularly SapBERT's self-alignment pretraining on UMLS synonyms~\cite{liu2021sapbert}, achieve strong performance mapping surface forms to canonical concepts. This machinery enables extracted findings to be represented in ontology-grounded form suitable for concept-based modeling.

\subsection{Vision-Language Models in Medical Imaging}

Contrastive pretraining on image-text pairs offers an alternative path to leveraging reports. CLIP's success~\cite{radford2021clip} prompted medical adaptations: ConVIRT~\cite{zhang2022convirt}, MedCLIP~\cite{wang2022medclip}, and BiomedCLIP~\cite{zhang2023biomedclip} align radiograph and report representations, enabling zero-shot classification through textual prompting. These approaches handle unpaired data and transfer flexibly across tasks. However, learned representations remain entangled rather than decomposed into discrete concepts, trading interpretable structure for representational flexibility~\cite{yang2023language}.

The components for concept-based chest radiograph modeling, including clinical NLP, entity linking, concept architectures, and vision-language alignment, exist but remain fragmented. This work integrates them into a pipeline that produces structured concept banks from report archives, enabling concept-based modeling at institutional scale.
