Deep learning has made chest X-ray classification increasingly accurate, but its predictions remain opaque at the point of care.
When a network flags pneumonia, clinicians cannot tell whether the evidence comes from a true parenchymal opacity or from shortcuts such as support devices, laterality markers, or acquisition artifacts.
This opacity is problematic because chest X-ray models generalize inconsistently across hospitals and scanners~\cite{zech2018variable}, leaving clinicians with little more than guesswork when failures occur.
Radiologists, by contrast, justify their impressions by anchoring findings to anatomy and explicitly ruling out alternatives, for example ``left lower lobe opacity, no pleural effusion.''
A clinically useful classifier should expose a similar, anatomy-linked rationale rather than a single uninterpretable score.

Concept bottleneck models (CBMs) offer a principled approach~\cite{koh2020concept}.
Instead of mapping images directly to labels, CBMs first predict human-interpretable concepts, then compute labels as explicit functions of those concepts.
When done well, this architecture is inherently transparent: each label decomposes into contributions from named findings, and clinicians can intervene by editing concepts rather than pixels.
The problem is supervision.
Classical CBMs require dense concept labels for every training image, and chest X-ray datasets contain hundreds of thousands of studies with 50 to 200 relevant findings each.
Annotating concepts at this scale would require millions of radiologist judgments, a non-starter for most institutions.

Recent work has attacked this drawback from several angles.
Label-free CBMs~\cite{oikarinen2023labelfree} use CLIP and GPT-generated concept lists to build concept layers without manual annotation, scaling to ImageNet.
Post-hoc CBMs~\cite{yuksekgonul2023posthoc} project pretrained embeddings onto concept subspaces, avoiding end-to-end retraining.
Concept Embedding Models~\cite{zarlenga2022cem} learn high-dimensional concept representations that improve the accuracy-interpretability trade-off.
These methods reduce annotation burden, but for radiology applications they typically derive their concepts from generic sources (language models, ConceptNet, or small curated sets) that are not grounded in clinical ontologies or visually validated for radiology.
In chest X-rays specifically, LLM-generated concepts can hallucinate findings, CLIP-based projections conflate visually similar but clinically distinct entities, and small concept sets like CheXpert's 14 labels miss the long tail of region-specific findings that radiologists routinely describe.
Moreover, flat CBMs, whether label-free, post-hoc, or supervised, treat all concepts as exchangeable, ignoring the anatomy-first structure of radiological reasoning.
This leads to implausible activations: lung findings firing when the lungs are predicted normal, or cardiac concepts co-activating in obviously healthy hearts.

Radiology reports offer a different kind of supervision.
Every chest X-ray comes with a report, and every report describes region-specific observations: opacities, effusions, masses, each tied to anatomy.
A sentence like ``patchy opacity in the left lower lobe consistent with pneumonia; no effusion; heart size normal'' implicitly labels the presence of lung opacity and the absence of pleural effusion and cardiomegaly.
These labels are noisy, because reports contain non-visual information, hedged language, and inconsistent phrasing, but they exist at scale, for free, and they are grounded in clinical practice rather than generated by a language model.
The question is whether they can supervise a CBM that respects clinical structure.

We show that they can.
\radcbm\ extracts observation-anatomy pairs from reports using RadGraph~\cite{jain2021radgraph}, normalizes them to SNOMED CT concepts within the UMLS so that the vocabulary inherits established clinical ontologies, filters to visually testable semantic types, and organizes the result into a two-level hierarchy: anatomical regions (lung, heart, pleura, mediastinum, bone) and region-specific findings.
A two-level predictor first estimates whether each region is abnormal, then predicts findings within that region, with multiplicative gating so that findings activate only when their region is flagged.
A linear head maps the gated concepts to diagnostic labels.
This design enforces clinical consistency (lung findings cannot fire if the lungs are predicted normal) and produces explanations that mirror how radiologists structure reports.

For such a system to be clinically useful, its explanations must satisfy two constraints: they must be faithful to the model's actual decision process, and they must remain consistent with how radiologists organize findings by anatomy.
Existing CBM variants often compromise on one of these axes: post-hoc projections can misattribute what drove a prediction, while unconstrained concept spaces allow implausible combinations of activations.
Our goal is a chest X-ray classifier in which concepts genuinely mediate predictions and are organized to reflect radiological reasoning, so that concept edits lead to predictable changes in labels and clinically inconsistent explanations are structurally disfavored.

We evaluate on MIMIC-CXR and CheXpert.
Automated concept extraction yields several hundred region-specific concepts, covering the long tail of findings that fixed label sets like CheXpert's 14 classes miss.
The hierarchical CBM improves concept prediction over flat CBMs, reduces implausible activations (e.g., cardiac findings in normal hearts), and matches black-box classification accuracy while exposing faithful, editable explanations.
Ablations confirm that both the hierarchy and the gating contribute: removing either degrades concept fidelity or plausibility.
Compared to Label-free and Post-hoc CBMs, \radcbm\ achieves higher intervention faithfulness because concepts are trained end-to-end on the prediction path with clinically grounded supervision.

Our contributions are:
\begin{itemize}
    \item A pipeline that extracts soft, ontology-grounded concept targets from radiology reports using RadGraph and UMLS (SNOMED CT) normalization, eliminating manual annotation while covering hundreds of region-specific findings anchored in clinical terminology.
    \item A hierarchical CBM with multiplicative gating that enforces region-finding consistency, structurally suppresses implausible activations, and produces explanations aligned with radiologist workflows.
    \item Experiments on MIMIC-CXR and CheXpert showing that automated concepts retain broad coverage, the hierarchy improves concept fidelity over flat and post-hoc CBMs, and classification matches black-box accuracy while enabling faithful concept interventions.
\end{itemize}
